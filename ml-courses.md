# ML Courses

| |
|-|
| [Large Language Models](#large-language-models) |
| [Deep Learning](#deep-learning) |
| [Machine Learning](#machine-learning) |
| [Data Engineering ](#data-engineering) |

 
## Large Language Models

* [HuggingFace Transformers Course](https://huggingface.co/course/chapter1/1): This course will teach you about natural language processing (NLP) using libraries from the Hugging Face ecosystem — Transformers, Datasets, Tokenizers, and Accelerate — as well as the Hugging Face Hub. It’s completely free and without ads.

* [ChatGPT and Large Language Models (LLMs): A Practical Guide](https://zerotomastery.io/courses/large-language-models/): This course is designed to give you a deep understanding of how to use LLMs like ChatGPT, and how they work under-the-hood. That means you'll learn about concepts like Prompt Design and Fine-Tuning so that you understand how models are trained and even how to train your own model.

* [MIT Future of AI is Foundation Models & Self-Supervised Learning](https://www.futureofai.mit.edu/): In this non-technical series of lectures, we will start with the history of AI, then with what supervised learning and reinforcement learning is missing, and conclude with the deep practical and foundational implications of self-supervised learning and foundation models.

* [Stanford CS25 - Transformers United](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM): In this seminar, we examine the details of how transformers work, and dive deep into the different kinds of transformers and how they're applied in different fields.

* [COS 597G (Fall 2022): Understanding Large Language Models by Princeton University](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/): This course is intended to prepare you for performing cutting-edge research in natural language processing, especially topics related to pre-trained language models. This is an advanced graduate course and all the students are expected to have taken machine learning and NLP courses before and are familiar with deep learning models such as Transformers.

* [Rasa Algorithm Whiteboard - Transformers & Attention (Large Language Models)](https://www.youtube.com/watch?v=yGTUuEx3GkA&list=PL75e0qA87dlG-za8eLI6t0_Pbxafk-cxb&index=10): This Youtube course provides an explanation of the attention mechanisms.

* [CS324 lecture notes on Large Language Models (Winter 2022)](https://stanford-cs324.github.io/winter2022/lectures/): This is a course on understanding and developing large language models. Another related course is [CS 324 - Advances in Foundation Models](https://stanford-cs324.github.io/winter2023/) ([Github](https://github.com/stanford-cs324)). Note: No video lectures available for these two courses. 

* [CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/):  In this course, students gain a thorough introduction to cutting-edge neural networks for NLP. I highly recommend the CS224N suggested reading list.


## Deep Learning

* [Introduction to Deep Learning and Generative Modeling by Sebastian Raschka](https://www.youtube.com/watch?v=1nqCZqDYPp0&list=PLTKMiZHVd_2KJtIXOW0zFhFfBaJJilH51)

* [DeepMind x UCL | Deep Learning Lecture Series 2020](https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF): In this lecture series,  research scientists from leading AI research lab, DeepMind, delivered 12 lectures on an exciting selection of topics in Deep Learning, ranging from the fundamentals of training neural networks via advanced ideas around memory, attention, and generative modelling to the important topic of responsible innovation.

* [MIT 6.S191: Introduction to Deep Learning](https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI): Through this course,  students will gain foundational knowledge of deep learning algorithms.

* [Deep Learning Drizzle](https://deep-learning-drizzle.github.io/): A website rich of courses on ML, AI, Graph neural network, reinforcement learning, natural language processing, etc. 

* [Neural networks for NLP (CMU CS 11-747, Spring 2021), Carnegie Mellon University](https://www.phontron.com/class/nn4nlp2021/schedule.html):  It covers major topics in neural networks modeling and training, e.g., Language modeling and training tricks,  Neural networks building, Recurrent neural networks, Attention mechanism and efficiency tricks, Contextual word representations, Debugging neural networks, Model interpretation, Trees and Graphs, Reinforcement learning for structured prediction, Knowledge bases with neural networks, and Adversarial methods and advanced search algorithms.

* [Learn Computer Vision From Top Universities](https://medium.com/mlearning-ai/learn-computer-vision-from-top-universities-bb6019be74d2): the article provides courses in several domains, including image and signal processing, computer vision, machine learning and deep learning for computer vision, programming for Computer Vision, and Photogrammetry.

* [Stanford CS330: Deep Multi-Task and Meta Learning](https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5): This is a graduate-level course. By the end of the course, students will be able to understand and implement the state-of-the-art multi-task learning and meta-learning algorithms and be ready to conduct research on these topics.
	* [Fall 2022 Update](https://cs330.stanford.edu/): The course has been updated by removing material on reinforcement learning and meta-reinforcement learning, and replacing it with content on self-supervised pre-training for few-shot learning (e.g. contrastive learning, masked language modeling) and transfer learning (e.g. domain adaptation and domain generalization). [Slides](https://cs330.stanford.edu/lecture_slides/), [Video lectures](https://www.youtube.com/watch?v=bkVCAk9Nsss&list=PLoROMvodv4rNjRoawgt72BBNwL2V7doGI)

* [Deep Learning at VU University Amsterdam](https://dlvu.github.io/): This page contains all public information about the course Deep Learning at the Vrije Universiteit Amsterdam.

* [Natural Language Processing with Hugging Face](https://www.youtube.com/playlist?app=desktop&list=PLxqBkZuBynVQEvXfJpq3smfuKq3AiNW-N): Various topics and models to deal with NLP problems. 

* [CMU Multimodal Machine Learning course by LP Morency (Carnegie Mellon, 2022)](https://www.youtube.com/playlist?list=PL-Fhd_vrvisNM7pbbevXKAbT_Xmub37fA): The course presents the fundamental mathematical concepts in machine learning and deep learning relevant to the six main challenges in multimodal research: (1) representation, (2) alignment, (3) reasoning, (4) generation, (5) transference and (6) quantification. [Course website](https://cmu-multicomp-lab.github.io/mmml-course/fall2022/), [Code](https://lnkd.in/giUvF4hD) 


## Machine Learning

* [100-Days-Of-ML-Code](https://github.com/Avik-Jain/100-Days-Of-ML-Code): 100 Days of ML Coding for beginners. 

* [Harvard CS50’s Introduction to Artificial Intelligence with Python](https://cs50.harvard.edu/ai/2020/): This course explores the concepts and algorithms at the foundation of modern artificial intelligence, diving into the ideas that give rise to technologies like game-playing engines, handwriting recognition, and machine translation.

* [Introduction to Data-Centric AI, IAP 2023](https://dcai.csail.mit.edu/): This class covers algorithms to find and fix common issues in ML data and to construct better datasets, concentrating on data used in supervised learning tasks like classification. Video recordings of the lectures are available on [YouTube](https://www.youtube.com/playlist?list=PLnSYPjg2dHQKdig0vVbN-ZnEU0yNJ1mo5).

* [Introduction to Machine Learning by Sebastian Raschka](https://sebastianraschka.com/blog/2021/ml-course.html): Video Lectures about Python Basics, Tree-based Methods, Model Evaluation, and Feature Selection. 

* [Introduction to machine learning and statistical pattern classification by Sebastian Raschka](https://www.youtube.com/watch?v=OgK8JFjkSto&list=PLTKMiZHVd_2KyGirGEvKlniaWeLOHhUF3)

* [openHPI Self-paced Courses](https://open.hpi.de/courses?q=&channel=&lang=&topic=Big+Data+and+AI&level=): plenty of courses in English and German related to ML, knowledge graphs, big data management, operating systems, and programming. 

* [Applied Machine Learning (Cornell Tech CS 5787, Fall 2020)](https://www.youtube.com/playlist?list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83): Starting from the very basics, the course covers all of the most important ML algorithms and how to apply them in practice. The slides are also Jupyter notebooks with programmatically generated figures (GitHub)[https://github.com/kuleshov/cornell-cs5785-2020-applied-ml]. 

* [Machine Learning Course Notes](https://github.com/dair-ai/ML-Course-Notes): This repository shares videos and lecture notes on several topics related to ML, NLP, Transformers, and Deep Reinforcement Learning.

* [𝐈𝐧𝐭𝐫𝐨𝐝𝐮𝐜𝐭𝐢𝐨𝐧 𝐭𝐨 𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 — 𝐔𝐂 𝐁𝐞𝐫𝐤𝐞𝐥𝐞𝐲](https://lnkd.in/dChzX6dZ): This class introduces algorithms for learning, which constitute an important part of artificial intelligence.

* [𝐈𝐧𝐭𝐫𝐨𝐝𝐮𝐜𝐭𝐢𝐨𝐧 𝐭𝐨 𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 — 𝐂𝐚𝐫𝐧𝐞𝐠𝐢𝐞 𝐌𝐞𝐥𝐥𝐨𝐧 𝐔𝐧𝐢𝐯𝐞𝐫𝐬𝐢𝐭𝐲](https://lnkd.in/dH8ktatw): This course is designed to give a graduate-level student a thorough grounding in the methodologies, technologies, mathematics and algorithms currently needed by people who do research in machine learning.

* [Machine Learning -- Stanford University by Andrew Ng](https://lnkd.in/d4FzSKpJ):  In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself.

* [𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 & 𝐃𝐚𝐭𝐚 𝐌𝐢𝐧𝐢𝐧𝐠 — 𝐂𝐚𝐥𝐭𝐞𝐜𝐡](https://lnkd.in/dUhbEyBx): This course will cover popular methods in machine learning and data mining, with an emphasis on developing a working understanding of how to apply these methods in practice. This course will also cover core foundational concepts underpinning and motivating modern machine learning and data mining approaches. This course will also cover some recent research developments.

* [𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐟𝐫𝐨𝐦 𝐃𝐚𝐭𝐚 — 𝐂𝐚𝐥𝐭𝐞𝐜𝐡](https://lnkd.in/d4zZZJ5h): This is an introductory course in machine learning (ML) that covers the basic theory, algorithms, and applications.

* [𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐟𝐨𝐫 𝐈𝐧𝐭𝐞𝐥𝐥𝐢𝐠𝐞𝐧𝐭 𝐒𝐲𝐬𝐭𝐞𝐦𝐬  —  𝐂𝐨𝐫𝐧𝐞𝐥𝐥 𝐔𝐧𝐢𝐯𝐞𝐫𝐬𝐢𝐭𝐲](https://lnkd.in/dtSjQ22i): This course will introduce the fundamental set of techniques and algorithms that constitute machine learning as of today, ranging from classification methods like decision trees and support vector machines, over structured models like hidden Markov models, to clustering and matrix factorization methods for recommendation.

* [𝐋𝐚𝐫𝐠𝐞 𝐒𝐜𝐚𝐥𝐞 𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠  — 𝐔𝐧𝐢𝐯𝐞𝐫𝐬𝐢𝐭𝐲 𝐨𝐟 𝐓𝐨𝐫𝐨𝐧𝐭𝐨](https://lnkd.in/dv8-7EFE): This is an advanced graduate course, designed for Master's and Ph.D. level students, and will assume a reasonable degree of mathematical maturity. 

* [𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐰𝐢𝐭𝐡 𝐋𝐚𝐫𝐠𝐞 𝐃𝐚𝐭𝐚𝐬𝐞𝐭𝐬— 𝐂𝐚𝐫𝐧𝐞𝐠𝐢𝐞 𝐌𝐞𝐥𝐥𝐨𝐧 𝐔𝐧𝐢𝐯𝐞𝐫𝐬𝐢𝐭𝐲, Fall 2022](https://10605.github.io/): This course is intended to provide a student with the mathematical, algorithmic, and practical knowledge of issues involving learning with large datasets. Among the topics considered are: data cleaning, visualization, and pre-processing at scale; principles of parallel and distributed computing for machine learning; techniques for scalable deep learning; analysis of programs in terms of memory, computation, and (for parallel methods) communication complexity; and methods for low-latency inference.

* [𝐅𝐨𝐮𝐧𝐝𝐚𝐭𝐢𝐨𝐧𝐬 𝐨𝐟 𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐚𝐧𝐝 𝐒𝐭𝐚𝐭𝐢𝐬𝐭𝐢𝐜𝐚𝐥 𝐈𝐧𝐟𝐞𝐫𝐞𝐧𝐜𝐞 — 𝐂𝐚𝐥𝐭𝐞𝐜𝐡 by Anima Anandkumar](https://lnkd.in/d9J9iksZ): This course will cover core concepts in machine learning and statistical inference. The ML concepts covered are spectral methods (matrices and tensors), non-convex optimization, probabilistic models, neural networks, representation theory, and generalization ([Lecture Notes](http://tensorlab.cms.caltech.edu/users/anima/cms165-2020.html)).

* [𝐒𝐭𝐚𝐭𝐢𝐬𝐭𝐢𝐜𝐚𝐥 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 — 𝐒𝐭𝐚𝐧𝐟𝐨𝐫𝐝 𝐔𝐧𝐢𝐯𝐞𝐫𝐬𝐢𝐭𝐲](https://lnkd.in/dKttsi_3): This is an introductory-level course in supervised learning, with a focus on regression and classification methods. The syllabus includes: linear and polynomial regression, logistic regression and linear discriminant analysis; cross-validation and the bootstrap, model selection and regularization methods (ridge and lasso); nonlinear models, splines and generalized additive models; tree-based methods, random forests and boosting; support-vector machines; neural networks and deep learning; survival models; multiple testing. Some unsupervised learning methods are discussed: principal components and clustering (k-means and hierarchical).

* [Learn AI from Top Universities Through these 10 Courses](https://pub.towardsai.net/learn-ai-from-top-universities-through-these-10-courses-13e7a8d3957b): This article introduces ten courses from top universities that will help you to have a better understanding of different concepts in AI and ML.

* [Machine Learning for Beginners - A Curriculum](https://github.com/microsoft/ML-For-Beginners): In this curriculum, you will learn about what is sometimes called classic ML, using primarily Scikit-learn as a library and avoiding deep learning.

* [Stanford CS229: Machine Learning](https://cs229.stanford.edu/syllabus-summer2020.html): The course a broad introduction to statistical machine learning (at an intermediate / advanced level) and covers supervised learning (generative/discriminative learning, parametric/non-parametric learning, neural networks, support vector machines); unsupervised learning (clustering, dimensionality reduction, kernel methods); learning theory (bias/variance tradeoffs, practical ); and reinforcement learning among other topics.

* [Statistical Machine Learning — Ulrike von Luxburg, 2020](https://www.youtube.com/playlist?list=PL05umP7R6ij2XCvrRzLokX6EoHWaGA2cC): The course covers the standard paradigms and algorithms in statistical machine learning, simply browse through the titles of the individual lectures to get an impression of the contents. The target audience consists of master students in computer science and related fields. 

* [Kimia Lab: Machine Intelligence](https://www.youtube.com/playlist?list=PLZWvneBOrhoEWyByqPli18AScodr_MzEK): An overview of different learning schemes will be provided: Decision Tree, Bayesian, Inductive, Analytical, and Rule-based learning. 

* [Tübingen Machine Learning](https://www.youtube.com/channel/UCupmCsCA5CFXmm31PkUhEbA): A series of wonderful ML courses delivered at Tübingen University.


## Data Engineering 

* [Data Engineering Zoomcamp](https://github.com/DataTalksClub/data-engineering-zoomcamp): Week 1: Introduction & Prerequisites, Week 2: Workflow Orchestration, Week 3: Data Warehouse, Week 4: Analytics Engineering, Week 5: Batch processing, Week 6: Streaming, and Week 7, 8 & 9: Project

* [CS839 Data Management for Machine Learning Applications](https://thodrek.github.io/CS839_spring18/): The goal of this seminar course is to study data management challenges that arise in the context of machine learning pipelines. The focus will be on cutting-edge problems in the context of ML pipelines, related to (1) data exploration and understanding, (2) data integration, cleaning, and validation, and (3) data preparation for ML models and serving of production ML applications. 

* [Data Engineering Foundations Specialization -- Enroll for Free](https://www.coursera.org/specializations/data-engineering-foundations#courses): The Specialization consists of 5 self-paced online courses covering skills required for data engineering, including the data engineering ecosystem and lifecycle, Python, SQL, and Relational Databases.  You will learn these data engineering prerequisites through engaging videos and hands-on practice using real tools and real-world databases. 

* [15-445/645 Intro to Database Systems (Spring 2023)](https://15445.courses.cs.cmu.edu/spring2023/): This course is on the design and implementation of database management systems. Topics include data models (relational, document, key/value), storage models (n-ary, decomposition), query languages (SQL, stored procedures), storage architectures (heaps, log-structured), indexing (order preserving trees, hash tables), transaction processing (ACID, concurrency control), recovery (logging, checkpoints), query processing (joins, sorting, aggregation, optimization), and parallel architectures (multi-core, distributed).  
