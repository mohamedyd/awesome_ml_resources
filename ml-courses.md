# ML Courses

This page contains plenty of courses in various topics, including:
* [Large Language Models](#large-language-models)
* [Deep Learning](#deep-learning) 
* [Machine Learning](#machine-learning) 
* [Data Engineering ](#data-engineering) 

 
## Large Language Models

* [Harvard CS197: AI Research Experiences](https://www.cs197.seas.harvard.edu/): This course will also teach you how to systematically read research papers, generate new ideas, and present them in slides or papers. You'll even learn valuable project management and team communication techniques used by top AI researchers. 

* [generative-ai-for-beginners by Microsoft](https://github.com/microsoft/generative-ai-for-beginners): Learn the fundamentals of building Generative AI applications with our 12-lesson comprehensive course by Microsoft Cloud Advocates. Each lesson covers a key aspect of Generative AI principles and application development. Throughout this course, we will be building our own Generative AI startup so you can get an understanding of what it takes to launch your ideas.

* [Large Language Models: Foundation Models from the Ground Up](https://www.youtube.com/playlist?list=PLTPXxbhUt-YWjMCDahwdVye8HW69p5NYS): This course dives into the details of LLM foundation models. You will learn the innovations that led to the proliferation of transformer-based architectures, from encoder models (BERT) to decoder models (GPT), to encoder-decoder models (T5). You will also learn about the recent breakthroughs that led to applications like ChatGPT.

* [hands-on-llms](https://github.com/iusztinpaul/hands-on-llms): Learn how to engineer your end-to-end LLM ecosystem: training, streaming, and inference pipelines | deploy & automate | work in progress...

* [LLMOps: Building Real-World Applications With Large Language Models](https://www.comet.com/site/llm-course/): Learn to build modern software with LLMs using the newest tools and techniques in the field. 

* [The Attention Mechanism in Large Language Models](https://www.youtube.com/playlist?list=PLs8w1Cdi-zva4fwKkl9EK13siFvL9Wewf): The first video is about self-attention and its intuition. The second video is about multi-head attention, and the math behind it.  The third video is about the entire architecture on transformer models. For all videos, only a basic understanding of high school math is needed. (The channel includes easy to grasp ML courses for begineers.)

* [LLM in Production Part I](https://www.youtube.com/playlist?list=PL3vkEKxWd-us5YvvuvYkjP_QGlgUq3tpA): A continuously updated podcast talks and lectures on "LLMs in Production" by MLOps Community has some 50+ talks on topics like Efficiently scaling and deploying Large Language Models, Obstacles faced while deploying LLMs, Ensuring accuracy and quality in LLM Driven products, and Large model training and inferencing with DeepSeepd library ([Part II](https://www.youtube.com/playlist?list=PL3vkEKxWd-uupBSWL-DbVJuCMqXO9Z3Z4))

* [Generative AI Foundations on AWS Technical Deep Dive Series](https://www.youtube.com/playlist?list=PLhr1KZpdzukf-xb0lmiU3G89GJXaDbAIF): Generative AI Foundations on AWS is a technical deep dive course that gives you the conceptual fundamentals, practical advice, and hands-on guidance to pre-train, fine-tune, and deploy state-of-the-art foundation models on AWS and beyond.

* [Generative AI learning path by Google](https://www.cloudskillsboost.google/journeys/118): This learning path guides you through a curated collection of content on generative AI products and technologies, from the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud.

* [Practical Large Language Models](https://www.youtube.com/playlist?list=PLB1nTQo4_y6ukBQYuQm0ZAmuj51hVMKrC): These are videos from a Practical LLM workshop organized by Aggregate Intellect. 

* [Development with Large Language Models Tutorial – OpenAI, Langchain, Agents, Chroma](https://www.youtube.com/watch?v=xZDB1naRUlk): FreeCodeCamp released another data science course focusing on LLM Engineering. This two hours course focuses on how to embed an LLM model on your own project using tools such as OpenAI, Langchain, Agents, Chroma, etc ([Colab Notebook](https://colab.research.google.com/drive/1gi2yDvvhUwLT7c8ZEXz6Yja3cG5P2owP?usp=sharing), [Source Code](https://github.com/pythonontheplane123/LLM_course_part_1)).

* [Getting Started with Generative AI](https://www.youtube.com/playlist?list=PLTzg8WR1gEHyngMtdoflAdQryg29-mPiL): In this video playlist, we will explore how we can use pre-trained models available in Hugging Face for Generative AI applications like Chat bot, Translation, Document Parsing, etc.

* [UMass CS685: Advanced Natural Language Processing (Spring 2023) by Mohit Iyyer](https://www.youtube.com/playlist?list=PLWnsVgP6CzaelCF_jmn5HrpOXzRAPNjWj): The course covers a lot of important topics critical to understanding generative ai and language models better N-Gram Models, Forward propagation in neural language models, Attention mechanisms and Transformer Language Models, Configuring transformer models and self attention models, Large Language Models, Parameter efficient adaptation and Instruction Tuning, Reinforecement Learning from Human Feedback (RHLF), Prompt engineering and augented LMs.

* [LangChain & Vector Databases in Production](https://learn.activeloop.ai/courses/langchain): Activeloop team has created a no-nonsense, applied course teaching how to build Application on Top of Large Language Models. 

* [Large Language Models: Application through Production by Databricks](https://www.youtube.com/playlist?list=PLTPXxbhUt-YWSR8wtILixhZLF9qB_1yZm): This course is aimed at developers, data scientists, and engineers looking to build LLM-centric applications with the latest and most popular frameworks. By the end of this course, you will have built an end-to-end LLM workflow that is ready for production!

* [LangChain: Chat with Your Data](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/): The course delves into two main topics: (1) Retrieval Augmented Generation (RAG), a common LLM application that retrieves contextual documents from an external dataset, and (2) a guide to building a chatbot that responds to queries based on the content of your documents, rather than the information it has learned in training.

* [100% Offline ChatGPT Alternative? by Rob Mulla](https://www.youtube.com/watch?v=Coj72EzmX20): In this video, Rob showed how he was able to install an open source Large Language Model (LLM) called h2oGPT on his local computer for 100% private, 100% local chat with a GPT.

* [Prompt Engineering Course: How To Effectively Use ChatGPT & Other AI Language Models](https://www.youtube.com/playlist?list=PLYio3GBcDKsPP2_zuxEp8eCulgFjI5a3g): Learn the basics of prompt engineering, Gain an understanding of what makes a good & bad prompt, Find out how to create, evaluate, and refine your prompts, Learn about some advanced techniques that will help you make your outputs more random or funny, and much more!

* [LLM Avalanche by FunctionalTV](https://www.youtube.com/playlist?list=PLNESult6cnOmbG_Sh0Y6-PxWjDaxOuZVB): LLM Avalanche is a technical Large-Language Model (ChatGPT and the like) meetup held in San Francisco on Jun 26, 2023, preceding the Data+AI Summit.

* [Learn the fundamentals of generative AI for real-world applications by Andrew Ng](https://www.deeplearning.ai/courses/generative-ai-with-llms/): Gain foundational knowledge, practical skills, and a functional understanding of how generative AI works.

* [Hands-on training transformers by San Diego Machine Learning](https://www.youtube.com/playlist?list=PLmp4AHm0u1g0_dp3KViUFepC-xDsQIrS_): Get to understand the working of transformers which form the core of generative ai models. The training has 5 one hour long sessions on Understanding data preparation, Knowledge on pretraining models, Model finetuning for specific use-cases, and Inferencing and deployment strategies.

* [Learn about AI Language Models and Reinforcement Learning](https://www.youtube.com/playlist?list=PLbzjzOKeYPCpp3NCeQioevM0YpZa5VqcS): From GPT-3.5-turbo to RL algorithms, this playlist covers everything you need to know about these cutting-edge technologies. Whether you're a student, a researcher, or a tech enthusiast, this playlist will expand your knowledge and help you stay up-to-date with the latest trends in AI.

* [State of GPT by Andrej Karpathy](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2): Learn about the training pipeline of GPT assistants like ChatGPT, from tokenization to pretraining, supervised finetuning, and Reinforcement Learning from Human Feedback (RLHF). Dive deeper into practical techniques and mental models for the effective use of these models, including prompting strategies, finetuning, the rapidly growing ecosystem of tools, and their future extensions.

* [LLM Bootcamp - Spring 2023 The Full Stack](https://www.youtube.com/playlist?list=PL1T8fO7ArWleyIqOy37OVXsP4hFXymdOZ): The course teaches you launching your first LLM app, foundational knowledge for LLMs, performing knowledge retrieval, and deploying these models to production.

* [ChatGPT Prompt Engineering for Developers by Andrew Ng and Isa Fulford](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/): Learn prompt engineering best practices for application development

* [ChatGPT Course – Use The OpenAI API to Code 5 Projects](https://www.youtube.com/watch?v=uRQH2CFvedY): Learn how to use the OpenAI API to create five projects, including a ChatGPT clone, a DALL-E Image Creator, and a SQL Generator. This is a dive deep into the world of the OpenAI API, exploring its diverse capabilities and potential applications.

* [HuggingFace Transformers Course](https://huggingface.co/course/chapter1/1): This course will teach you about natural language processing (NLP) using libraries from the Hugging Face ecosystem — Transformers, Datasets, Tokenizers, and Accelerate — as well as the Hugging Face Hub. It’s completely free and without ads.

* [ChatGPT and Large Language Models (LLMs): A Practical Guide](https://zerotomastery.io/courses/large-language-models/): This course is designed to give you a deep understanding of how to use LLMs like ChatGPT, and how they work under-the-hood. That means you'll learn about concepts like Prompt Design and Fine-Tuning so that you understand how models are trained and even how to train your own model.

* [LangChain](https://www.youtube.com/playlist?list=PLqZXAkvF1bPNQER9mLmDbntNfSpzdDIU5): LangChain is a framework for developing applications powered by language models. In short, it allows you to connect the OpenAI API to Google Drive, Gmail, or YouTube API.

* [MIT Future of AI is Foundation Models & Self-Supervised Learning](https://www.futureofai.mit.edu/): In this non-technical series of lectures, we will start with the history of AI, then with what supervised learning and reinforcement learning is missing, and conclude with the deep practical and foundational implications of self-supervised learning and foundation models.

* [Stanford CS25 - Transformers United](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM): In this seminar, we examine the details of how transformers work, and dive deep into the different kinds of transformers and how they're applied in different fields.

* [COS 597G (Fall 2022): Understanding Large Language Models by Princeton University](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/): This course is intended to prepare you for performing cutting-edge research in natural language processing, especially topics related to pre-trained language models. This is an advanced graduate course and all the students are expected to have taken machine learning and NLP courses before and are familiar with deep learning models such as Transformers.

* [Rasa Algorithm Whiteboard - Transformers & Attention (Large Language Models)](https://www.youtube.com/watch?v=yGTUuEx3GkA&list=PL75e0qA87dlG-za8eLI6t0_Pbxafk-cxb&index=10): This Youtube course provides an explanation of the attention mechanisms.

* [CS324 lecture notes on Large Language Models (Winter 2022)](https://stanford-cs324.github.io/winter2022/lectures/): This is a course on understanding and developing large language models. Another related course is [CS 324 - Advances in Foundation Models](https://stanford-cs324.github.io/winter2023/) ([Github](https://github.com/stanford-cs324)). Note: No video lectures available for these two courses. 

* [CS224N: Natural Language Processing with Deep Learning](https://web.stanford.edu/class/cs224n/):  In this course, students gain a thorough introduction to cutting-edge neural networks for NLP. I highly recommend the CS224N suggested reading list.

* [Stanford XCS224U: Natural Language Understanding](https://www.youtube.com/playlist?list=PLoROMvodv4rOwvldxftJTmoR3kRcWkJBp): This professional Stanford Online course draws on theoretical concepts from linguistics, natural language processing, and machine learning. Topics include domain adaptation for supervised sentiment, retrieval augmented in-context learning, advanced behavioral evolution, analysis methods, and NLP methods ([Source code](https://github.com/cgpotts/cs224u)).

## Deep Learning

* [Deep Learning Course by François Fleuret](https://fleuret.org/dlc/): This course is a thorough introduction to deep-learning, with examples in the PyTorch framework: machine learning objectives and main challenges, tensor operations, automatic differentiation, gradient descent, deep-learning specific techniques, generative, recurrent, attention models. 

* [Deep Learning & Reinforcement Learning by Chris G. Willcocks](https://cwkx.github.io/teaching.html): Two courses discussing the basics and advanced topics in deep learning, generative AI, and reinforcement learning.

* [Computer Vision in Practice by Roboflow](https://www.youtube.com/playlist?list=PLZCA39VpuaZajiCtgDDwU8ghchtqx347R): Bundle of video tutorials showing how to train Computer Vision models and how to use them in practice.

* [Practical Deep Learning for Coders - part 2](https://www.youtube.com/playlist?list=PLfYUBJiXbdtRUvTUYpLdfHHp9a58nWVXP): In this course, containing over 30 hours of video content, we implement the astounding Stable Diffusion algorithm from scratch! That’s the killer app that made the internet freak out, and caused the media to say “you may never believe what you see online again”.

* [Neural Networks: Zero to Hero by Andrej Karpathy](https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ): This practical course introduces the main concepts of deep learning models, including WaveNet and GPT, through teaching you how to implement them from scrtach. 

* [Introduction to Deep Learning and Generative Modeling by Sebastian Raschka](https://www.youtube.com/watch?v=1nqCZqDYPp0&list=PLTKMiZHVd_2KJtIXOW0zFhFfBaJJilH51)

* [DeepMind x UCL | Deep Learning Lecture Series 2020](https://www.youtube.com/playlist?list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF): In this lecture series,  research scientists from leading AI research lab, DeepMind, delivered 12 lectures on an exciting selection of topics in Deep Learning, ranging from the fundamentals of training neural networks via advanced ideas around memory, attention, and generative modelling to the important topic of responsible innovation.

* [MIT 6.S191: Introduction to Deep Learning](https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI): Through this course,  students will gain foundational knowledge of deep learning algorithms.

* [Deep Learning Drizzle](https://deep-learning-drizzle.github.io/): A website rich of courses on ML, AI, Graph neural network, reinforcement learning, natural language processing, etc. 

* [Neural networks for NLP (CMU CS 11-747, Spring 2021), Carnegie Mellon University](https://www.phontron.com/class/nn4nlp2021/schedule.html):  It covers major topics in neural networks modeling and training, e.g., Language modeling and training tricks,  Neural networks building, Recurrent neural networks, Attention mechanism and efficiency tricks, Contextual word representations, Debugging neural networks, Model interpretation, Trees and Graphs, Reinforcement learning for structured prediction, Knowledge bases with neural networks, and Adversarial methods and advanced search algorithms.

* [Learn Computer Vision From Top Universities](https://medium.com/mlearning-ai/learn-computer-vision-from-top-universities-bb6019be74d2): the article provides courses in several domains, including image and signal processing, computer vision, machine learning and deep learning for computer vision, programming for Computer Vision, and Photogrammetry.

* [Stanford CS330: Deep Multi-Task and Meta Learning](https://www.youtube.com/playlist?list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5): This is a graduate-level course. By the end of the course, students will be able to understand and implement the state-of-the-art multi-task learning and meta-learning algorithms and be ready to conduct research on these topics.
	* [Fall 2022 Update](https://cs330.stanford.edu/): The course has been updated by removing material on reinforcement learning and meta-reinforcement learning, and replacing it with content on self-supervised pre-training for few-shot learning (e.g. contrastive learning, masked language modeling) and transfer learning (e.g. domain adaptation and domain generalization). [Slides](https://cs330.stanford.edu/lecture_slides/), [Video lectures](https://www.youtube.com/watch?v=bkVCAk9Nsss&list=PLoROMvodv4rNjRoawgt72BBNwL2V7doGI)

* [Deep Learning at VU University Amsterdam](https://dlvu.github.io/): This page contains all public information about the course Deep Learning at the Vrije Universiteit Amsterdam.

* [Natural Language Processing with Hugging Face](https://www.youtube.com/playlist?app=desktop&list=PLxqBkZuBynVQEvXfJpq3smfuKq3AiNW-N): Various topics and models to deal with NLP problems. 

* [CMU Multimodal Machine Learning course by LP Morency (Carnegie Mellon, 2022)](https://www.youtube.com/playlist?list=PL-Fhd_vrvisNM7pbbevXKAbT_Xmub37fA): The course presents the fundamental mathematical concepts in machine learning and deep learning relevant to the six main challenges in multimodal research: (1) representation, (2) alignment, (3) reasoning, (4) generation, (5) transference and (6) quantification. [Course website](https://cmu-multicomp-lab.github.io/mmml-course/fall2022/), [Code](https://lnkd.in/giUvF4hD) 


## Machine Learning

* [Introduction to Machine Learning by Melih Kandemir](https://melihkandemir.github.io/teaching/): Melih prepared all the material as Jupyter notebooks that show theory and implementation side by side.

* [100-Days-Of-ML-Code](https://github.com/Avik-Jain/100-Days-Of-ML-Code): 100 Days of ML Coding for beginners. 

* [Harvard CS50’s Introduction to Artificial Intelligence with Python](https://cs50.harvard.edu/ai/2020/): This course explores the concepts and algorithms at the foundation of modern artificial intelligence, diving into the ideas that give rise to technologies like game-playing engines, handwriting recognition, and machine translation.

* [Introduction to Data-Centric AI, IAP 2023](https://dcai.csail.mit.edu/): This class covers algorithms to find and fix common issues in ML data and to construct better datasets, concentrating on data used in supervised learning tasks like classification. Video recordings of the lectures are available on [YouTube](https://www.youtube.com/playlist?list=PLnSYPjg2dHQKdig0vVbN-ZnEU0yNJ1mo5).

* [Introduction to Machine Learning by Sebastian Raschka](https://sebastianraschka.com/blog/2021/ml-course.html): Video Lectures about Python Basics, Tree-based Methods, Model Evaluation, and Feature Selection. 

* [Introduction to machine learning and statistical pattern classification by Sebastian Raschka](https://www.youtube.com/watch?v=OgK8JFjkSto&list=PLTKMiZHVd_2KyGirGEvKlniaWeLOHhUF3)

* [openHPI Self-paced Courses](https://open.hpi.de/courses?q=&channel=&lang=&topic=Big+Data+and+AI&level=): plenty of courses in English and German related to ML, knowledge graphs, big data management, operating systems, and programming. 

* [Applied Machine Learning (Cornell Tech CS 5787, Fall 2020)](https://www.youtube.com/playlist?list=PL2UML_KCiC0UlY7iCQDSiGDMovaupqc83): Starting from the very basics, the course covers all of the most important ML algorithms and how to apply them in practice. The slides are also Jupyter notebooks with programmatically generated figures (GitHub)[https://github.com/kuleshov/cornell-cs5785-2020-applied-ml]. 

* [Machine Learning Course Notes](https://github.com/dair-ai/ML-Course-Notes): This repository shares videos and lecture notes on several topics related to ML, NLP, Transformers, and Deep Reinforcement Learning.

* [𝐈𝐧𝐭𝐫𝐨𝐝𝐮𝐜𝐭𝐢𝐨𝐧 𝐭𝐨 𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 — 𝐔𝐂 𝐁𝐞𝐫𝐤𝐞𝐥𝐞𝐲](https://lnkd.in/dChzX6dZ): This class introduces algorithms for learning, which constitute an important part of artificial intelligence.

* [𝐈𝐧𝐭𝐫𝐨𝐝𝐮𝐜𝐭𝐢𝐨𝐧 𝐭𝐨 𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 — 𝐂𝐚𝐫𝐧𝐞𝐠𝐢𝐞 𝐌𝐞𝐥𝐥𝐨𝐧 𝐔𝐧𝐢𝐯𝐞𝐫𝐬𝐢𝐭𝐲](https://lnkd.in/dH8ktatw): This course is designed to give a graduate-level student a thorough grounding in the methodologies, technologies, mathematics and algorithms currently needed by people who do research in machine learning.

* [Machine Learning -- Stanford University by Andrew Ng](https://lnkd.in/d4FzSKpJ):  In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself.

* [𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 & 𝐃𝐚𝐭𝐚 𝐌𝐢𝐧𝐢𝐧𝐠 — 𝐂𝐚𝐥𝐭𝐞𝐜𝐡](https://lnkd.in/dUhbEyBx): This course will cover popular methods in machine learning and data mining, with an emphasis on developing a working understanding of how to apply these methods in practice. This course will also cover core foundational concepts underpinning and motivating modern machine learning and data mining approaches. This course will also cover some recent research developments.

* [𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐟𝐫𝐨𝐦 𝐃𝐚𝐭𝐚 — 𝐂𝐚𝐥𝐭𝐞𝐜𝐡](https://lnkd.in/d4zZZJ5h): This is an introductory course in machine learning (ML) that covers the basic theory, algorithms, and applications.

* [𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐟𝐨𝐫 𝐈𝐧𝐭𝐞𝐥𝐥𝐢𝐠𝐞𝐧𝐭 𝐒𝐲𝐬𝐭𝐞𝐦𝐬  —  𝐂𝐨𝐫𝐧𝐞𝐥𝐥 𝐔𝐧𝐢𝐯𝐞𝐫𝐬𝐢𝐭𝐲](https://lnkd.in/dtSjQ22i): This course will introduce the fundamental set of techniques and algorithms that constitute machine learning as of today, ranging from classification methods like decision trees and support vector machines, over structured models like hidden Markov models, to clustering and matrix factorization methods for recommendation.

* [𝐋𝐚𝐫𝐠𝐞 𝐒𝐜𝐚𝐥𝐞 𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠  — 𝐔𝐧𝐢𝐯𝐞𝐫𝐬𝐢𝐭𝐲 𝐨𝐟 𝐓𝐨𝐫𝐨𝐧𝐭𝐨](https://lnkd.in/dv8-7EFE): This is an advanced graduate course, designed for Master's and Ph.D. level students, and will assume a reasonable degree of mathematical maturity. 

* [𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐰𝐢𝐭𝐡 𝐋𝐚𝐫𝐠𝐞 𝐃𝐚𝐭𝐚𝐬𝐞𝐭𝐬— 𝐂𝐚𝐫𝐧𝐞𝐠𝐢𝐞 𝐌𝐞𝐥𝐥𝐨𝐧 𝐔𝐧𝐢𝐯𝐞𝐫𝐬𝐢𝐭𝐲, Fall 2022](https://10605.github.io/): This course is intended to provide a student with the mathematical, algorithmic, and practical knowledge of issues involving learning with large datasets. Among the topics considered are: data cleaning, visualization, and pre-processing at scale; principles of parallel and distributed computing for machine learning; techniques for scalable deep learning; analysis of programs in terms of memory, computation, and (for parallel methods) communication complexity; and methods for low-latency inference.

* [𝐅𝐨𝐮𝐧𝐝𝐚𝐭𝐢𝐨𝐧𝐬 𝐨𝐟 𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐚𝐧𝐝 𝐒𝐭𝐚𝐭𝐢𝐬𝐭𝐢𝐜𝐚𝐥 𝐈𝐧𝐟𝐞𝐫𝐞𝐧𝐜𝐞 — 𝐂𝐚𝐥𝐭𝐞𝐜𝐡 by Anima Anandkumar](https://lnkd.in/d9J9iksZ): This course will cover core concepts in machine learning and statistical inference. The ML concepts covered are spectral methods (matrices and tensors), non-convex optimization, probabilistic models, neural networks, representation theory, and generalization ([Lecture Notes](http://tensorlab.cms.caltech.edu/users/anima/cms165-2020.html)).

* [𝐒𝐭𝐚𝐭𝐢𝐬𝐭𝐢𝐜𝐚𝐥 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 — 𝐒𝐭𝐚𝐧𝐟𝐨𝐫𝐝 𝐔𝐧𝐢𝐯𝐞𝐫𝐬𝐢𝐭𝐲](https://lnkd.in/dKttsi_3): This is an introductory-level course in supervised learning, with a focus on regression and classification methods. The syllabus includes: linear and polynomial regression, logistic regression and linear discriminant analysis; cross-validation and the bootstrap, model selection and regularization methods (ridge and lasso); nonlinear models, splines and generalized additive models; tree-based methods, random forests and boosting; support-vector machines; neural networks and deep learning; survival models; multiple testing. Some unsupervised learning methods are discussed: principal components and clustering (k-means and hierarchical).

* [Learn AI from Top Universities Through these 10 Courses](https://pub.towardsai.net/learn-ai-from-top-universities-through-these-10-courses-13e7a8d3957b): This article introduces ten courses from top universities that will help you to have a better understanding of different concepts in AI and ML.

* [Machine Learning for Beginners - A Curriculum](https://github.com/microsoft/ML-For-Beginners): In this curriculum, you will learn about what is sometimes called classic ML, using primarily Scikit-learn as a library and avoiding deep learning.

* [Stanford CS229: Machine Learning](https://cs229.stanford.edu/syllabus-summer2020.html): The course a broad introduction to statistical machine learning (at an intermediate / advanced level) and covers supervised learning (generative/discriminative learning, parametric/non-parametric learning, neural networks, support vector machines); unsupervised learning (clustering, dimensionality reduction, kernel methods); learning theory (bias/variance tradeoffs, practical ); and reinforcement learning among other topics.

* [Statistical Machine Learning — Ulrike von Luxburg, 2020](https://www.youtube.com/playlist?list=PL05umP7R6ij2XCvrRzLokX6EoHWaGA2cC): The course covers the standard paradigms and algorithms in statistical machine learning, simply browse through the titles of the individual lectures to get an impression of the contents. The target audience consists of master students in computer science and related fields. 

* [Kimia Lab: Machine Intelligence](https://www.youtube.com/playlist?list=PLZWvneBOrhoEWyByqPli18AScodr_MzEK): An overview of different learning schemes will be provided: Decision Tree, Bayesian, Inductive, Analytical, and Rule-based learning. 

* [Tübingen Machine Learning](https://www.youtube.com/channel/UCupmCsCA5CFXmm31PkUhEbA): A series of wonderful ML courses delivered at Tübingen University.


## Data Engineering 

* [Introduction to Data-Centric AI, MIT IAP 2023](https://www.youtube.com/playlist?list=PLnSYPjg2dHQKdig0vVbN-ZnEU0yNJ1mo5): A course by MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) talks about the focus on data over model Data Annotation and Label Errors, Dataset creation and curation, Class imbalance, outliers, and distribution shift, Growing datasets, Interpretability and evaluation, Data augmentation, privacy and security. 

* [Data Engineering Zoomcamp](https://github.com/DataTalksClub/data-engineering-zoomcamp): Week 1: Introduction & Prerequisites, Week 2: Workflow Orchestration, Week 3: Data Warehouse, Week 4: Analytics Engineering, Week 5: Batch processing, Week 6: Streaming, and Week 7, 8 & 9: Project

* [CS839 Data Management for Machine Learning Applications](https://thodrek.github.io/CS839_spring18/): The goal of this seminar course is to study data management challenges that arise in the context of machine learning pipelines. The focus will be on cutting-edge problems in the context of ML pipelines, related to (1) data exploration and understanding, (2) data integration, cleaning, and validation, and (3) data preparation for ML models and serving of production ML applications. 

* [Data Engineering Foundations Specialization -- Enroll for Free](https://www.coursera.org/specializations/data-engineering-foundations#courses): The Specialization consists of 5 self-paced online courses covering skills required for data engineering, including the data engineering ecosystem and lifecycle, Python, SQL, and Relational Databases.  You will learn these data engineering prerequisites through engaging videos and hands-on practice using real tools and real-world databases. 

* [15-445/645 Intro to Database Systems (Spring 2023)](https://15445.courses.cs.cmu.edu/spring2023/): This course is on the design and implementation of database management systems. Topics include data models (relational, document, key/value), storage models (n-ary, decomposition), query languages (SQL, stored procedures), storage architectures (heaps, log-structured), indexing (order preserving trees, hash tables), transaction processing (ACID, concurrency control), recovery (logging, checkpoints), query processing (joins, sorting, aggregation, optimization), and parallel architectures (multi-core, distributed).  
