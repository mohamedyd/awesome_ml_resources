| Chapter | Topic                        | Ideas                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Resources                                                        |
|---------|------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------|
| 1       | Summary                      | • **ML**: Learn complex patterns from existing data and use these patterns to make predictions on unseen data<br>• **Zero-shot and continual learning**: Two approaches to learn with small data or no data<br>• **ML shines if**: The problem is repetitive, the cost of a wrong prediction is cheap, it's at scale, patterns are constantly changing<br>• **Key differences**: Between ML in research and in production<br>• **ML Systems versus Traditional Software**: Highlighting the distinct characteristics of ML systems compared to standard software |                                                              |
| 2       | Summary                      | • **Characteristics of ML systems**: Most should have reliability, scalability, maintainability, adaptability<br>• **Decoupling objectives**: It's good practice to simplify the model development & maintenance as mentioned on pages 41-43                                    |                              |
| 3       | Summary                      | • **First-party data**: Data your company collects about your customers.<br>• **Second-party data**: Data collected by another company about their own customers and made available to you.<br>• **Third-party data**: Companies collect data on the public who are not their direct customers.<br>• **Data formats**: JSON, row-Major (CSV), column-major (Parquet).<br>• **Data Models**: Relational data, NoSQL (document model, e.g., JSON, XML, BSON, and graph model).<br>• **Normalization in databases**: A good practice to reduce redundancy and improve integration.<br>• **Languages**: SQL is declarative; Python is imperative.<br>• **Query optimizer**: Examines all possible ways to execute a query and selects the fastest one.<br>• **Declarative ML**: User declares the features' schema and the task, the system then finds the best model.<br>• **Structured vs. Unstructured data**: Structured data follows predefined schema; unstructured data does not but may contain intrinsic patterns.<br>• **OLTP vs. OLAP**: Online transactional processing involves users; online analytical processing aggregates data in columns.<br>• **ETL**: Process to extract, transform, and load data into the target destination.<br>• **Modes of data flow**: Through databases, services, or real-time transport (e.g., Kafka). |                                                              |
| 11      | Infrastructure abstraction   | • It is difficult for data scientists to equally focus on model development and on model deployment. <br>• However, there are several drawbacks for splitting the team into ML engineers and DevOps engineers:<br>    - Communication and coordination overhead<br>    - Debugging challenges: when trying to figure out where the failures come from<br>    - Finger-pointing: each team might think it's another team's responsibility to fix the failures<br>    - Narrow context: no one has visibility into the entire process to optimize it<br>• A solution to this dilemma is to allow data scientists to own the entire process end-to-end without having to worry about the infrastructure:<br>    - What if I can tell the tool, "Here where I store my data (S3), here are the steps to run my code (featurization, modeling), here's where my code should run (EC2 instances, serverless stuff like AWS Batch, Functions, etc.), here's what my code needs to run at each step (dependencies)," and then this tool manages all the infrastructure stuff for the data scientist.<br>• Can we use large language models to generate configuration files for each infrastructure generated by such a tool? | • MLOps templates, e.g., <br>Cookiecutter template for MLOps<br>• MLOps Guide<br>• DagsHub / Cookiecutter-MLOps<br>    - A reasonably standardized but flexible project structure that implements sound MLOps principles for building your next machine learning project <br>    - It includes only DVC<br>• mlops-generator 1.0.1 <br>    - CLI for MLOps code generator |