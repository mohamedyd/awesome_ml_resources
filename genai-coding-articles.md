
# Articles on Coding with LLMs

## Domain-specific Coding with LLMs

* [A Survey on LLM-based Code Generation for Low-Resource and Domain-Specific Programming Languages](https://arxiv.org/pdf/2410.03981?): The survey provides a systematic review of the current state, methodologies, and challenges in leveraging LLMs for code generation in Domain-Specfic Languages. The survey categorizes the methods used for LLM improvement into six main groups and summarized the novel methods and architectures proposed by the researchers. 

* [On the Effectiveness of Large Language Models in Domain-Specific Code Generation](https://arxiv.org/pdf/2312.01639): The study demonstrates that LLMs exhibit sub-optimal performance in generating domain-specific code, due to their limited proficiency in utilizing domain-specific libraries. We further observe that incorporating API knowledge as prompts can empower LLMs to generate more professional code.

* [The potential of LLMs for coding with low-resource and domain-specific programming languages](https://arxiv.org/pdf/2307.13018): The study suggests that LLMs can be a useful tool for writing, understanding, improving, and documenting gretl code, which includes generating descriptive docstrings for functions and providing precise explanations for abstract and poorly documented econometric code.

* [Grammar Prompting for Domain-Specific Language Generation with Large Language Models](https://proceedings.neurips.cc/paper_files/paper/2023/file/cd40d0d65bfebb894ccc9ea822b47fa8-Paper-Conference.pdf): The article proposes grammar prompting, a simple approach to enable LLMs to use external knowledge and domain-specific constraints, expressed through a grammar in Backusâ€“Naur Form (BNF), during in-context learning.

* [DSL-Xpert: LLM-driven Generic DSL Code Generation](https://dl.acm.org/doi/pdf/10.1145/3652620.3687782?casa_token=xpbmFqLswCQAAAAA:_T8rVHsUmA85RDbiM-hInnzCEOGMv6yLbefI-huaGNt0rg5kLI9V5eV3Gans183kCZezot0g7dBc): This paper presents a tool in which developers can perform what is known as semantic parsing. In other words, the developer can ask a pre-trained LLM to translate a natural language instruction into the vocabulary of the established DSL. Thus, by setting the DSL grammar as context (grammar prompting) and providing usage examples (few-shot learning), the LLM can quickly generate reliable domain-specific code

* [MONOCODER: Domain-Specific Code Language Model for HPC Codes and Tasks](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10938441&casa_token=jN11230yH9YAAAAA:v02BO2mwyVtzYWlsCzuB1MiqNbxwpgKKwXxyfbZW3y_Q8DSbP0QaGzDviwZa3bf3eZAIChWu8g&tag=1): The study questions choices made by existing LLMs by developing smaller language models (LMs) for specific domains -- the authors call them domain-specific LMs. Specifically, The study starts with High-Performance Computing (HPC) as a domain and builds an HPC-specific LM, named MONOCODER, which is orders of magnitude smaller than existing LMs but delivers better performance on non-HPC and HPC codes.

## General Coding with LLMs 

* [Paradigm shift on Coding Productivity Using GenAI (2025)](https://arxiv.org/pdf/2504.18404?): Through surveys and interviews with industrial domain-experts, the authors identify primary productivity-influencing factors, including task complexity, coding skills, domain knowledge, and GenAI integration. The findings indicate that GenAI tools enhance productivity in routine coding tasks (e.g., refactoring and Javadoc generation) but face challenges in complex, domain-specific activities due to limited context-awareness of codebases and insufficient support for customized design rules.

* [A Survey on Large Language Models for Code Generation](https://arxiv.org/pdf/2406.00515): The survey, published in 2024, categorizes and discusses the recent developments in LLMs for code generation, covering aspects such as data curation, latest advances, performance evaluation, ethical implications, environmental impact, and real-world applications.

* [A Survey of Large Language Models for Code: Evolution, Benchmarking, and Future Trends](https://arxiv.org/pdf/2311.10372): The survey, published in 2024, addresses three
questions: (1) What LLMs are specifically designed for software engineering tasks, and their relationship? (2) Do Code LLMs outperform general LLMs in software engineering tasks? (3) Which LLMs are more proficient in different software engineering tasks? 

* [Code LLMs: A Taxonomy-based Survey](https://arxiv.org/pdf/2412.08291): this survey, published in 2024, offers insights into the current state and future directions of LLMs in coding tasks, including their applications and limitations.

* [Using an LLM to Help With Code Understanding](https://dl.acm.org/doi/pdf/10.1145/3597503.3639187): the study investigates the effectiveness of generation-based information support using LLMs to aid developers in code understanding.



## Blog Posts

* [7 Ways GenAI Can Help Improve Software Development](https://www.oracle.com/de/artificial-intelligence/generative-ai/generative-ai-software-development/): The blog post discusses seven ways in which Generative AI can help improve software development, including code generation, code review, and code documentation.

* [Generative AI in Software Engineering: Scenarios and Challenges Ahead](https://www.iese.fraunhofer.de/blog/generative-ai-in-software-engineering-scenarios-and-challenges/): This post discusses the future scenarios for the adoption of GenAI in Software Development. 

* [Security risks of AI-generated code and how to manage them](https://www.techtarget.com/searchsecurity/tip/Security-risks-of-AI-generated-code-and-how-to-manage-them): The article discusses the security risks of AI-generated code and provides strategies for managing them. 