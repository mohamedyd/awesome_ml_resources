# ML blogs & Articles 

This page contains plenty of blogs and articles on various ML topics, including:

* [Large Language Models](#large-language-models)
* [Traditional ML and Deep Learning](#traditional-ml--dl)


## Large Language Models

* [Large Language Model Cheatsheet](https://docs.google.com/presentation/d/1ytGfwc8tIKolDQ_jMOmhWVC8t41klYa5/edit?usp=share_link&ouid=100484802817147345492&rtpof=true&sd=true): three slides summairzing the main ideas and concepts of large language models.

* [How to train your own Large Language Models?](https://blog.replit.com/llm-training): The blog post explains how to train your own custom large language models, using MosaicML, Databricks, and Hugging Face. 

* [Building LLM applications for production](https://huyenchip.com/2023/04/11/llm-engineering.html): This awesome post consists of three parts:
	- Part 1 discusses the key challenges of productionizing LLM applications and the solutions that I’ve seen.
    - Part 2 discusses how to compose multiple tasks with control flows (e.g. if statement, for loop) and incorporate tools (e.g. SQL executor, bash, web browsers, third-party APIs) for more complex and powerful applications.
	- Part 3 covers some of the promising use cases that I’ve seen companies building on top of LLMs and how to construct them from smaller tasks.
	
* [Understanding Large Language Models -- A Transformative Reading List by Sebastian Raschka](https://sebastianraschka.com/blog/2023/llm-reading-list.html): The author collected important research papers to understand the large language models. The reading list will help you understand the breakthroughs in the NLP space over the years: from RNNs in the pre-transformer era to Google BERT to today’s ChatGPT.

* [Jay Alammar’s Article Series on Large Language Models](https://medium.com/geekculture/top-resoruces-to-learn-understand-large-language-models-4d339f7b685d): Jay has written multiple blogs on transformers and large language models that are really impressive and very unique to understanding the basics of large language models.

* [Transformer models: an introduction and catalog — 2023 Edition](https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/): A Catalog of Transformer AI models.

* [What Is ChatGPT Doing … and Why Does It Work?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/): An in-depth explanation of how ChatGPT works and what really lets ChatGPT work?

* [𝗛𝘂𝗻𝗱𝗿𝗲𝗱𝘀 𝗼𝗳 𝗡𝗟𝗣 𝗣𝗮𝗽𝗲𝗿𝘀 𝘄𝗶𝘁𝗵 𝗖𝗼𝗱𝗲](https://index.quantumstat.com/): The NLP Index lets you keep track of the NLP advancements, by offering an updated list of the latest NLP research papers! Furthermore, the website provides a link for the Github repository of each paper, making it a valuable resource for ML researchers and practitioners.

* [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223): In this survey, the authors review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, they focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation.


## Traditional ML & DL

* [ML-Papers-Explained](https://github.com/dair-ai/ML-Papers-Explained): Explanations to key concepts in ML.

* [Machine Learning Mastery](https://machinelearningmastery.com/start-here/):  Step-by-step guides for getting started with applied ML. 

* [Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI](https://arxiv.org/abs/2201.00650): This reference is a home to hundreds of fully-solved problems, from a wide range of key topics in AI.

* [From Zero to AI Research Scientist Full Resources Guide](https://github.com/ahmedbahaaeldin/From-0-to-Research-Scientist-resources-guide): A guide for anyone with basic programming knowledge or a computer science background interested in becoming a Research Scientist with 🎯 on Deep Learning and NLP.

* [Awesome AI Guidelines](https://github.com/EthicalML/awesome-artificial-intelligence-guidelines): This repository maps the ecosystem of guidelines, principles, codes of ethics, standards and regulation being put in place around artificial intelligence.

* [Papers With Code: The latest in Machine Learning](https://paperswithcode.com/): A list of machine learning papers, their datasets, and their source code.

* [labml.ai Annotated PyTorch Paper Implementations](https://nn.labml.ai/): A collection of simple PyTorch implementations of neural networks and related algorithms. These implementations are documented with explanations, and the website renders these as side-by-side formatted notes.

* [Your Guide to Data Quality Management](https://www.scnsoft.com/blog/guide-to-data-quality-management): tips on how a company can measure and improve the quality of their data.

* [Deep Learning Tuning Playbook, Google & Harvard](https://github.com/google-research/tuning_playbook): If you have ever wondered about the process of hyperparameter tuning, this guide is for you. 

* [FloydHub Blog](https://blog.floydhub.com/): A list of articles about all topics in AI, books recommendation, datasets, etc.

* [Awesome-conformal-prediction](https://github.com/valeman/awesome-conformal-prediction): The most comprehensive professionally curated resource on Conformal Prediction including the best tutorials, videos, books, papers, articles, courses, websites, conferences and open-source libraries code in Python, R and Julia.

* [The Base Camp for your Ascent in Machine Learning](https://databasecamp.de/en/homepage): In this blog, you will find all the topics to help you master the expedition into the world of Artificial Intelligence. 

* [CS 229 ― Machine Learning](https://stanford.edu/~shervine/teaching/cs-229/): A set of illustrated ML cheatsheets covering the content of the CS 229 class at Stanford.

