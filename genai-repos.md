# Generative AI Repositories

This page contains a list of repositories related to Generative AI, Large Language Models (LLMs), and Natural Language Processing (NLP). 

* [GenAI Agents: Comprehensive Repository for Development and Implementation](https://github.com/NirDiamant/GenAI_Agents): This repository serves as a comprehensive resource for learning, building, and sharing GenAI agents, ranging from simple conversational bots to complex, multi-agent systems.

* [Agents Towards Production](https://github.com/NirDiamant/agents-towards-production): Agents Towards Production is your go-to resource for building GenAI agents that scale - from zero to production.
Whether you're just starting or refining your deployment stack, this repo gives you the tools, patterns, and code examples to do it right.

* [FastAPI-Ignite Boilerplate](https://github.com/bakrianoo/fastapi-ignite): production-ready FastAPI boilerplate application with a comprehensive set of features for modern web backend development. It can be used while building API-based LLM applications. 

* [Hands-On Large Language Models](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models): In this repository, you will find the code for all examples throughout the book Hands-On Large Language Models written by Jay Alammar and Maarten Grootendorst.

* [Awesome LLM Apps](https://github.com/Shubhamsaboo/awesome-llm-apps): A curated collection of awesome LLM apps built with RAG and AI agents. This repository features LLM apps that use models from OpenAI, Anthropic, Google, and even open-source models like LLaMA that you can run locally on your computer.

* [End-to-End Gen AI App Starter Pack](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/gemini/sample-apps/e2e-gen-ai-app-starter-pack): Google's E2E GenAI App Starter Pack delivers production-ready GenAI tools on Google Cloud Platform. This includes: A LangGraph agent implementation, Built-in testing and monitoring, Seamless deployment with CI/CD and Terraform, and a user-friendly UI for experimentation. Fork, customize and use this resource to build and deploy GenAI apps faster.

* [Docling](https://ds4sd.github.io/docling/): ùë´ùíêùíÑùíçùíäùíèùíà: by IBM, supports different formats like PDF, DOCX, PPTX, XLSX, Images, HTML, AsciiDoc & Markdown, and exports to HTML, Markdown and JSON

* [Nougat: Neural Optical Understanding for Academic Documents](https://facebookresearch.github.io/nougat/): This is a tool developed by Meta to extract knowledge stored in books and scientific journals. This OCR system converts documents into a markup language.

* [Microsoft MarkItDown](https://github.com/microsoft/markitdown): a 100% open-source, one-stop solution for effortlessly converting any file to Markdown‚Äîperfect for text analysis, indexing, and more!

* [LLM Compressor](https://github.com/vllm-project/llm-compressor): an easy-to-use library for optimizing models for deployment. LLM Compressor is open-source, integrates with HugginFace model repositories, and is compatible with the most popular open-source inferencing systems, such as VLLM Project and Hugging Face.

* [How to use ngrok and colab to run large models for free? [Arabic]](https://lnkd.in/dsgbEGza): A trick to avoid costs of running GPUs while developing LLM applications.

* [PDF Parsing](https://github.com/0xthierry/llama-parse-cli): The "Llama Parse CLI" is a command-line tool for parsing complex documents into machine and LLM-readable formats. It uses the LlamaIndex Parser API to handle PDFs with text, tables, and images. This tool helps you convert documents to markdown or JSON with a simple terminal command, streamlining data preparation for LLM training and fine-tuning tasks.

* [Generative AI projects for your resume](https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/resources/gen_ai_projects.md): Boost your resume with these amazing Generative AI project ideas, each designed to provide practical experience and highlight your skills with the latest technologies.

* [LLM Explorer: A curated list of open-source LLM models](https://llm.extractum.io/): LLM EXPLORER catalogs about 35,000 open-source LLMs and features cool LLM categories like: Code Generating Models, Instruction-Based LLMs, Uncensored LLMs, LLMs Fit in 4GB RAM, Trending LLMs & Hot Picks and many more!

* [LLM-Finetuning](https://github.com/ashishpatel26/LLM-Finetuning): This project focuses on efficiently fine-tuning large language models using LoRA and Hugging Face's transformers library.

* [awesome-generative-ai-guide](https://github.com/aishwaryanr/awesome-generative-ai-guide): Generative AI is experiencing rapid growth, and this repository serves as a comprehensive hub for updates on generative AI research, interview materials, notebooks, and more!

* [Awesome LLM Interpretability](https://github.com/JShollaj/awesome-llm-interpretability): A curated list of amazingly awesome tools, papers, articles, and communities focused on Large Language Model (LLM) Interpretability.

* [10 GenAI Notebooks: OpenAI, LLM, RAG, GPT, and More](https://mltechniques.com/2023/12/01/10-genai-notebooks-openai-llm-rag-gpt-and-more/): For developers and AI/ML professionals. This comprehensive free resource offered by our sponsor is designed to provide you with hands-on experience and deeper insights into building cutting-edge GenAI applications.

* [LLM360](https://www.llm360.ai/): LLM360 introduces Amber and CrystalCoder, 7B parameter LLMs, offering full transparency in Large Language Model (LLM) training with comprehensive open-source release including training data and code.
 
* [LLM-Finetuning](https://github.com/ashishpatel26/LLM-Finetuning): A Collection of Colab Based LLMs Fine tuning Notebooks. This project focuses on efficiently fine-tuning large language models using LoRA and Hugging Face's transformers library.

* [Hallucination Leaderboard](https://github.com/vectara/hallucination-leaderboard): Public LLM leaderboard computed using Vectara's Hallucination Evaluation Model. This evaluates how often an LLM introduces hallucinations when summarizing a document. 

* [Llama 2 Fine-tuning / Inference Recipes, Examples, Benchmarks and Demo Apps](https://github.com/facebookresearch/llama-recipes/tree/main): The 'llama-recipes' repository is a companion to the Llama 2 model. The goal of this repository is to provide examples to quickly get started with fine-tuning for domain adaptation and how to run inference for the fine-tuned models.

* [Gorilla: Large Language Model Connected with Massive APIs](https://github.com/ShishirPatil/gorilla): Gorilla enables LLMs to use tools by invoking APIs. Given a natural language query, Gorilla comes up with the semantically- and syntactically- correct API to invoke. 

* [vLLM -- Easy, fast, and cheap LLM serving for everyone](https://github.com/vllm-project/vllm):  A high-throughput and memory-efficient inference and serving engine for LLMs 

* [GodMode - the smol AI Chat Browser](https://github.com/smol-ai/GodMode): This is a dedicated chat browser that only does one thing: help you quickly access the full webapps of ChatGPT, Claude 2, Perplexity, Bing and more with a single keyboard shortcut (Cmd+Shift+G).

* [AutoTrain Advanced](https://github.com/huggingface/autotrain-advanced): With AutoTrain Advanced, anyone can use colab to finetune LLMs just by uploading data and tuning parameters! All you need to do is create a folder called data and put your train.csv in it! Make sure it has text column, adjust params, model, etc, and boom your model will start training.

* [LlamaIndex](https://gpt-index.readthedocs.io/en/latest/): Connecting your own data with LLMs is a superpower to make these models really performant and useful, this is exactly where the LlamaIndex framework shines. 

* [H2O LLM studio by H2O.ai](https://github.com/h2oai/h2o-llmstudio): no-code toolkit to finetune large language models for multiple downstream applications. It's equipped with multiple finetuning techniques, such as Low-Rank Adaptation (LoRA) and Reinforcement Learning (RL). It also allows to track and evaluate finetuning experiments using Neptune toolkit and import/export models with Hugging Face

* [OpenLLM](https://github.com/bentoml/OpenLLM): An open platform for operating large language models (LLMs) in production. Fine-tune, serve, deploy, and monitor any LLMs with ease.

* [Prompt2Model - Generate Deployable Models from Instructions](https://github.com/neulab/prompt2model): Prompt2Model is a system that takes a natural language task description (like the prompts used for LLMs such as ChatGPT) to train a small special-purpose model that is conducive for deployment. 

* [Open LLMs](https://github.com/eugeneyan/open-llms): a list of LLMs (Large Language Models) that are all licensed for commercial use (e.g., Apache 2.0, MIT, OpenRAIL-M).

* [List of Open Sourced Fine-Tuned Large Language Models (LLM)](https://medium.com/geekculture/list-of-open-sourced-fine-tuned-large-language-models-llm-8d95a2e0dc76): An incomplete list of open-sourced fine-tuned Large Language Models (LLM) you can run locally on your computer. You can have most up and running for less than $100, including training dataset and GPU costs. 

* [Scikit-LLM: Sklearn Meets Large Language Models](https://github.com/iryna-kondr/scikit-llm): Seamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks.

* [StarCoder](https://huggingface.co/bigcode/starcoder): StarCoder is the first large model (15B) which is both high performance (beating the likes of PaLM, LLaMa, CodeGen or OpenAI code-crushman-001 on code generation) and also trained only on carefully vetted data.

* [Practical Guides for Large Language Models ](https://github.com/Mooler0410/LLMsPracticalGuide): A curated (still actively updated) list of practical guide resources of LLMs

* [Chat with Open Large Language Models](https://chat.lmsys.org/): The Chatbot Arena by FastChat enables sending a query to two LLMs in parallel and getting the answers side by side. The Chatbot Arena currently supports nine open-source LLMs, such as StableLM, LLaMA, Dolly, Alpaca, etc.

* [StructGPT](https://github.com/RUCAIBox/StructGPT): A general framework for Large Language Model to Reason on Structured Data

* [Auto-GPT](https://github.com/Significant-Gravitas/Auto-GPT): Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. Its main features are (1) Internet access for searches and information gathering, (2) Long-Term and Short-Term memory management, (3) GPT-4 instances for text generation, (4) Access to popular websites and platforms, and (5) File storage and summarization with GPT-3.5.(article: [Intro to Auto-GPT](https://autogpt.net/autogpt-step-by-step-full-setup-guide/), Videos: [Install Auto-GPT Locally](https://www.youtube.com/watch?app=desktop&v=0m0AbdoFLq4), [Create Your Personal AI Assistant](https://www.youtube.com/watch?app=desktop&v=jn8n212l3PQ)) Note: some practitioners reported that Auto-GPT fails to carry out 80% of the assigned tasks (date: April 17, 2023).

* [H2O LLM Studio](https://github.com/h2oai/h2o-llmstudio): a framework and no-code GUI designed for fine-tuning state-of-the-art large language models (LLMs). [Colab](https://colab.research.google.com/drive/1-OYccyTvmfa3r7cAquw8sioFFPJcn4R9?usp=sharing&pli=1&authuser=1#scrollTo=a5WqLjn4-chc)

* [HELM](https://crfm.stanford.edu/helm/latest/?): Holistic Evaluation of Language Models (HELM) is a living benchmark that aims to improve the transparency of language models. HELM evaluates 36 LLM models on the same scenarios with the same adaptation strategy (e.g., prompting), allowing for controlled comparisons. 

* [Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm): Databricks are open-sourcing the entirety of Dolly 2.0, including the training code, the dataset, and the model weights, all suitable for commercial use. This means that any organization can create, own, and customize powerful LLMs that can talk to people, without paying for API access or sharing data with third parties.

* [LLaMA](https://github.com/facebookresearch/llama): LLaMA is a collection of foundation language models ranging from 7B to 65B parameters. The models have been trained on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. More details can be found in this [blog post](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/).

* [ùêãùêöùêßùê†ùêúùê°ùêöùê¢ùêß 101: ùêÑùêöùê¨ùê¢ùêûùê¨ùê≠ ùê∞ùêöùê≤ ùê≠ùê® ùêõùêÆùê¢ùê•ùêù ùêãùêãùêå ùêöùê©ùê©ùê¨](https://docs.langchain.com/docs/): LangChain is a framework for developing applications powered by language models. Currrent use cases are Personal assistants, Question answering over database(s), Chatbots, Querying tabular data, Interacting with APIs, Model Evaluation. [Git Repo](https://lnkd.in/dSp5n3Sa), [Cookbook by Gregory Kamradt(Easy way to get started)](https://lnkd.in/dqQGMW5u), [Youtube Tutorials](https://lnkd.in/dh3rGuch)

* [FastChat](https://github.com/lm-sys/FastChat): An open platform for training, serving, and evaluating large language model based chatbots. The platform includes the Vicu√±a - an open-source chatbot based on Python created by a team of researchers from UC Berkeley, CMU, Stanford, and UC San Diego.

* [GPT4All](https://github.com/nomic-ai/gpt4all): Demo, data and code to train an assistant-style large language model with ~800k GPT-3.5-Turbo Generations based on LLaMa

* [Hugging Face](https://huggingface.co/): A list of datasets and pretrained-models for different ML applications
